# -*- coding: utf-8 -*-
"""Convolutional DAE for Bioacoustics Project (Synthetic Data)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YgIBsGjtyidc8m7YJy9dkW9kNetTjTDN
"""

import numpy as np
import matplotlib.pyplot as plt

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torch.autograd import Variable
from torchvision import transforms
from torchvision.datasets import MNIST
from torchvision.utils import save_image
from skimage import transform

from pathlib import Path
import time
import os

!pip install nvgpu
import nvgpu

"""Mount Google Drive."""

from google.colab import drive
drive.mount('/content/drive')

"""Define dataset class:"""

IM_HEIGHT = 100
IM_WIDTH = 24

class SpectrogramDataset(Dataset):
    """Spectrogram dataset."""
    
    def __init__(self, root_dir):
        self.root_dir = root_dir
    
    def __len__(self):
        #files = os.listdir(self.root_dir + '/spec_mix/')
        #files = [f for f in files if f[-4:] == '.csv']
        #return len(files)
        return 6000
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        
        spec_mix_name = self.root_dir + '/spec_mix/' + str(idx) + '.csv'
        spec_fg_name = self.root_dir + '/spec_fg/' + str(idx) + '.csv'
        spec_mix = np.genfromtxt(spec_mix_name, dtype='double')
        spec_fg = np.genfromtxt(spec_fg_name, dtype='double')
        #spec_mix = np.log(spec_mix + 0.001 * np.ones(spec_mix.shape))
        #spec_fg = 0.5 * np.log(spec_fg + 0.001 * np.ones(spec_fg.shape))

        spec_mix = transform.resize(spec_mix, (IM_HEIGHT, IM_WIDTH), anti_aliasing=True)
        spec_fg = 0.5 * transform.resize(spec_fg, (IM_HEIGHT, IM_WIDTH), anti_aliasing=True)
        
        spec_fg = spec_fg/np.max(spec_mix)
        spec_mix = spec_mix/np.max(spec_mix)
        #spec_mix = -1 * np.log(spec_mix + 0.001 * np.ones(spec_mix.shape))
        #spec_fg = -0.5 * np.log(spec_fg + 0.001 * np.ones(spec_fg.shape))
        sample = {'mix': spec_mix, 'fg': spec_fg}
        return sample

class SpectrogramDatasetPreloaded(Dataset):
    """Spectrogram dataset."""
    
    def __init__(self, root_dir, length):
        self.root_dir = root_dir
        self.length = length
        self.specs_mix = []
        self.specs_fg = []
        for i in np.arange(self.length):
          spec_mix_name = self.root_dir + '/spec_mix/' + str(i) + '.csv'
          spec_fg_name = self.root_dir + '/spec_fg/' + str(i) + '.csv'
          spec_mix = np.genfromtxt(spec_mix_name, dtype='double')
          spec_fg = np.genfromtxt(spec_fg_name, dtype='double')
          spec_mix = transform.resize(spec_mix, (IM_HEIGHT, IM_WIDTH), anti_aliasing=True)
          spec_fg = 0.5 * transform.resize(spec_fg, (IM_HEIGHT, IM_WIDTH), anti_aliasing=True)
          spec_fg = spec_fg/np.max(spec_mix)
          spec_mix = spec_mix/np.max(spec_mix)
          self.specs_mix.append(spec_mix)
          self.specs_fg.append(spec_fg)
          if (i % 200 == 0):
              print('Finished ' + str(i) + 'th image.')
    
    def __len__(self):
        return self.length
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        
        return {'mix': self.specs_mix[idx], 'fg': self.specs_fg[idx]}

# make an autoencoder class (with encoder and decoder, two layers each)
class autoencoder(nn.Module):
    def __init__(self, device):
        super(autoencoder, self).__init__()
        self.encoder = nn.Sequential(nn.Linear(25 * 100, 512), nn.ReLU(True), nn.Linear(512, 128), nn.ReLU(True))
        self.decoder = nn.Sequential(nn.Linear(128, 512), nn.ReLU(True), nn.Linear(512, 25 * 100), nn.Sigmoid())
        #self.encoder = nn.Sequential(nn.Linear(426 * 100, 4096), nn.ReLU(True), nn.Linear(4096, 1024), nn.ReLU(True))
        #self.decoder = nn.Sequential(nn.Linear(1024, 4096), nn.ReLU(True), nn.Linear(4096, 426 * 100), nn.ReLU(True))
        self.device = device
    
    def forward(self, x):
        x = self.encoder(x).to(self.device)
        x = self.decoder(x).to(self.device)
        return x

class convEncoder(nn.Module):
    def __init__(self, device):
        super(convEncoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=2, stride=2),
            nn.ReLU(True),
            nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=2, stride=2),
            nn.Sigmoid())
        self.device = device

    def forward(self, x):
        x = self.encoder(x).to(self.device)
        x = self.decoder(x).to(self.device)
        return x

"""Create (or open) dataset."""

import pickle

# set paths
#base = Path('/content/drive/My Drive/Synthetic_bird_data/synthetic_data_v2_3_zipped_folders')
base = Path('/content/drive/My Drive/Synthetic_bird_data/constructed_data_v1_zipped')

pickle_filename = base/'dataset_100x24'

CONSTRUCT_DATASET = False

if CONSTRUCT_DATASET:
    zip_path_bg = base/'spec_bg.zip'
    zip_path_fg = base/'spec_fg.zip'
    zip_path_mix = base/'spec_mix.zip'

    # copy over zip files
    t0 = time.time()
    #!cp "{zip_path_bg}" .
    !cp "{zip_path_fg}" .
    !cp "{zip_path_mix}" .
    t1 = time.time()
    print('Copy takes ' + str(t1 - t0) + ' sec.')

    t0 = time.time()
    #!unzip -q spec_bg.zip
    !unzip -q spec_fg.zip
    !unzip -q spec_mix.zip
    t1 = time.time()
    print('Unzip takes ' + str(t1 - t0) + ' sec.')

    t1 = time.time()
    full_dataset = SpectrogramDatasetPreloaded(root_dir='/content/', length=10000)
    t2 = time.time()
    print('Time to construct dataset: ' + str(t2 - t1))

    with open(pickle_filename, 'wb') as pickle_file:
        pickle.dump(full_dataset, pickle_file)
else:
    with open(pickle_filename, 'rb') as pickle_file:
        full_dataset = pickle.load(pickle_file)

full_dataset

# split into training and testing datasets.
batch_size = 64

train_size = int(0.8 * len(full_dataset))
test_size = len(full_dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])

train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

t1 = time.time()
spec_example = train_dataset[1]['fg']
t2 = time.time()

print('Dataset length: ' + str(len(train_dataset)))
print('Spectrogram size: (' + str(spec_example.shape[0]) + ', ' + str(spec_example.shape[1]) + ')')
print('Time to load spectrogram: ' + str(t2 - t1))
print('Dataset mix maximum and fg maximum: ' + str(np.max(train_dataset[0]['mix'])) + ', ' + str(np.max(train_dataset[0]['fg'])))

index = 50

mix_spec = train_dataset[index]['mix']
fg_spec = train_dataset[index]['fg']

plt.figure(figsize=(16, 6))
plt.subplot(1, 3, 1)
plt.imshow(np.transpose(mix_spec))
plt.title('Original Mixed Track')
plt.gca().invert_yaxis()
plt.colorbar()
plt.subplot(1, 3, 2)
plt.imshow(np.transpose(fg_spec))
plt.title('Original Birdsong Track')
plt.gca().invert_yaxis()
plt.colorbar()
plt.subplot(1, 3, 3)
plt.imshow(np.transpose(fg_spec - mix_spec))
plt.title('Difference')
plt.gca().invert_yaxis()
plt.colorbar()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

nvgpu.gpu_info()

torch.cuda.empty_cache()

nvgpu.gpu_info()

# define optimization parameters: number of epochs, batch size, and learning rate
num_epochs = 800
learning_rate = 1e-4

# define model, loss, and optimizer
model = convEncoder(device).to(device)
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0)

# make lists to store info
bce_loss_list = []
mse_loss_list = []
loss_test_list = []
loss_test_indices = []

# take one spectrogram as an example
index = 4
mix_spec_example = torch.from_numpy(train_dataset[index]['mix'])
fg_spec_example = train_dataset[index]['fg']

# train!
plt.figure(figsize=(18, 16))
counter = -1
subplot_counter = 0

i = 0
for epoch in range(num_epochs):
    for data in train_dataloader:
        counter = counter + 1
        # --- load data ---
        mix_spec = data['mix']
        fg_spec = data['fg']

        #mix_spec = data['mix'] + torch.from_numpy(np.ones(mix_spec.shape))
        #fg_spec = data['mix'] + torch.from_numpy(np.ones(fg_spec.shape))

        data_size, _, _ = mix_spec.shape
                
        # make into variables
        mix_spec = Variable(mix_spec.view(data_size, 1, IM_HEIGHT, IM_WIDTH)).float().to(device)
        fg_spec = Variable(fg_spec.view(data_size, 1, IM_HEIGHT, IM_WIDTH)).float().to(device)
        
        # --- forward ---
        output = model(mix_spec)
        loss = criterion(output, fg_spec)
        MSE_loss = nn.MSELoss()(output, fg_spec)
        
        # --- backward ---
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        mse_loss_list.append(MSE_loss.item())
        bce_loss_list.append(loss.item())
        #if (counter % 10 == 0):
        #print('batch [{}], loss:{:.4f}, MSE_loss:{:.4f}'.format(counter + 1, loss.item(), MSE_loss.item()))
        
        if (counter % 500 == 0):
          # plot every 500 batches
          output = model(mix_spec_example.view(1, 1, IM_HEIGHT, IM_WIDTH).float().to(device))
          output = output.cpu().detach().numpy()
          
          if (subplot_counter == 12):
            plt.figure(figsize=(18, 16))
            subplot_counter = 0
          
          plt.subplot(4, 3, subplot_counter + 1)
          subplot_counter = subplot_counter + 1
          plt.imshow(np.transpose(output[0,0,:,:]))
          plt.title("Iteration " + str(counter))
          plt.colorbar()
    
    if (epoch % 10 == 0):
        # evaluate model on test data
        with torch.no_grad():
          loss_test = 0
          test_counter = 0
          for test_data in test_dataloader:
              mix_spec_test = test_data['mix']
              fg_spec_test = test_data['fg']
              data_size_test, _, _ = mix_spec_test.shape
              # make into variables
              mix_spec_test = Variable(mix_spec_test.view(data_size_test, 1, IM_HEIGHT, IM_WIDTH)).float().to(device)
              fg_spec_test = Variable(fg_spec_test.view(data_size_test, 1, IM_HEIGHT, IM_WIDTH)).float().to(device)
              output_test = model(mix_spec_test)
              loss_test = loss_test + criterion(output_test, fg_spec_test)
              test_counter = test_counter + 1
        
        loss_test = loss_test/test_counter
        loss_test_list.append(loss_test)
        loss_test_indices.append(counter)
        print('--- epoch [{}/{}], train loss:{:.4f}, test loss: {:.4f}, MSE_loss:{:.4f}'.format(epoch+1, num_epochs, loss.item(), loss_test.item(), MSE_loss.item()))

#torch.save(model.state_dict(), './sim_dautoencoder.pth')
mix_spec.shape

from matplotlib import pyplot as plt

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(bce_loss_list, label='Training Set Loss')
plt.plot(loss_test_indices, loss_test_list, label='Test Set Loss')
plt.title('Loss Across Minibatches')
plt.xlabel('Minibatch Number')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(mse_loss_list, label='MSE Loss')
plt.title('MSE Loss')
plt.xlabel('Minibatch Number')
plt.ylabel('Loss')

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(np.log10(bce_loss_list), label='BCE Loss')
plt.plot(loss_test_indices, np.log10(loss_test_list), label='Test Set Loss')
plt.title('BCE Loss (log10-scale))')
plt.xlabel('Minibatch Number')
plt.ylabel('Log10 of Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(np.log10(mse_loss_list), label='MSE Loss')
plt.title('MSE Loss (log10-scale)')
plt.xlabel('Minibatch Number')
plt.ylabel('Log10 of Loss')

plt.figure(figsize=(12, 4))

plt.plot(np.log10(bce_loss_list), 'turquoise', label='Training Loss (minibatch)')
plt.plot(loss_test_indices, np.log10(loss_test_list), 'darkblue', label='Test Loss (full test dataset)')
plt.title('BCE Loss Across Minibatches (log-scale))')
plt.xlabel('Minibatch Number')
plt.ylabel('Log10 of BCE Loss')
plt.legend()

plt.savefig(base/'loss.eps')

nvgpu.gpu_info()

model.eval()

plt.figure(figsize=(18, 10))
#fig, ax = plt.subplots(figsize=(18, 16))
indices = [20, 21, 60]
for i in np.arange(len(indices)):
  mix_spec = test_dataset[indices[i]]['mix']
  fg_spec = test_dataset[indices[i]]['fg']
  output_tensor = model(torch.from_numpy(mix_spec).view(1, 1, IM_HEIGHT, IM_WIDTH).float().to(device)).cpu()
  output = np.reshape(output_tensor.detach().numpy(), (IM_HEIGHT, IM_WIDTH))
  plt.subplot(3, 3, i * 3 + 1)
  plt.imshow(np.transpose(mix_spec), extent=[0, 1, 8.5, 0], aspect=1/(4*8))
  plt.title('Original Mixed Track')
  plt.xlabel('Time (sec)')
  plt.ylabel('Frequency (kHz)')
  plt.gca().invert_yaxis()
  plt.colorbar()
  plt.subplot(3, 3, i * 3 + 2)
  plt.imshow(np.transpose(fg_spec), extent=[0, 1, 8.5, 0], aspect=1/(4*8))
  plt.title('Original Birdsong Track')
  plt.xlabel('Time (sec)')
  plt.ylabel('Frequency (kHz)')
  plt.gca().invert_yaxis()
  plt.colorbar()
  plt.subplot(3, 3, i * 3 + 3)
  plt.imshow(np.transpose(output), extent=[0, 1, 8.5, 0], aspect=1/(4*8))
  plt.title('DAE Output')
  plt.xlabel('Time (sec)')
  plt.ylabel('Frequency (kHz)')
  plt.gca().invert_yaxis()
  plt.colorbar()

plt.savefig(base/'spectrogram.eps')



plt.figure(figsize=(18, 16))
indices = [21, 22, 23, 24, 25]
for i in np.arange(len(indices)):
  mix_spec = test_dataset[indices[i]]['mix']
  fg_spec = dataset[indices[i]]['fg']
  input_value = np.reshape(mix_spec, (2500))
  output_tensor = model(torch.from_numpy(input_value).float().to(device)).cpu()
  output = np.reshape(output_tensor.detach().numpy(), (100, 25))
  plt.subplot(5, 3, i * 3 + 1)
  plt.imshow(np.log(np.transpose(mix_spec + 0.001 * np.ones(mix_spec.shape))))
  plt.title('Original Mixed Track')
  plt.gca().invert_yaxis()
  plt.colorbar()
  plt.subplot(5, 3, i * 3 + 2)
  plt.imshow(np.log(np.transpose(fg_spec + 0.001 * np.ones(mix_spec.shape))))
  plt.title('Original Birdsong Track')
  plt.gca().invert_yaxis()
  plt.colorbar()
  plt.subplot(5, 3, i * 3 + 3)
  plt.imshow(np.log(np.transpose(output + 0.001 * np.ones(mix_spec.shape))))
  plt.title('DAE Output')
  plt.gca().invert_yaxis()
  plt.colorbar()

index = 4

mix_spec = dataset[index]['mix']
fg_spec = dataset[index]['fg']

input_value = np.reshape(mix_spec, (2500))
output_tensor = model(torch.from_numpy(input_value).float().to(device)).cpu()
output = np.reshape(output_tensor.detach().numpy(), (100, 25))

output[0,0:10]

plt.figure()
plt.imshow(np.transpose(mix_spec))
plt.title('Original Mixed Track')
plt.gca().invert_yaxis()
plt.colorbar()
plt.figure()
plt.imshow(np.transpose(fg_spec))
plt.title('Original Birdsong Track')
plt.gca().invert_yaxis()
plt.colorbar()
plt.figure()
plt.imshow(np.transpose(output))
plt.title('DAE Output')
plt.gca().invert_yaxis()
plt.colorbar()

#plt.figure()
#plt.imshow(np.log(np.transpose(mix_spec + 0.001 * np.ones(mix_spec.shape))))
#plt.title('Original Mixed Track (log-scale)')
#plt.colorbar()
#plt.gca().invert_yaxis()
#plt.figure()
#plt.imshow(np.log(np.transpose(fg_spec + 0.001 * np.ones(mix_spec.shape))))
#plt.title('Original Birdsong Track (log-scale)')
#plt.colorbar()
#plt.gca().invert_yaxis()
#plt.figure()
#plt.imshow(np.log(np.transpose(output + 0.001 * np.ones(mix_spec.shape))))
#plt.title('DAE Output (log-scale)')
#plt.colorbar()
#plt.gca().invert_yaxis()